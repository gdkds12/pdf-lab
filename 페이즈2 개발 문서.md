```markdown
# Project Thunder 개발 작업 지시서 (Phase 2)
## Phase 2: Audio Signal Extraction & Query Generation (v3.0 최신) [file:1]

> Phase 2의 목적은 GCS 오디오를 분석해 **signals(신호)**를 구조화하여 DB에 저장하고, Phase 3에서 교재 근거를 찾기 위한 **search_queries**를 함께 생성하는 것이다. [file:1]  
> Phase 2는 “결론/최종 분류/근거 확정”을 하지 않으며, 판단은 Phase 4에서만 수행한다(Decision deferral). [file:1]

---

## 1) 목표와 출력(SSOT)
### 목표
- 오디오에서 시험과 관련된 발언을 놓치지 않고 “신호 단위”로 추출한다. [file:1]
- 각 신호마다 교재에서 근거를 찾기 위한 검색 의도(키워드형 query)를 2~6개 생성한다. [file:1]

### DB 저장(최종 산출물)
Target table: `signals` [file:1]

필수 컬럼(v3.0 SSOT):
- `session_id` (FK)
- `audio_chunk_id` (FK, NOT NULL)  ← UX/감사/리플레이 핵심 [file:1]
- `content` (한국어, 사용자 노출 가능)
- `signal_type` (예비 태그: hint|likely|trap)
- `t0_sec`, `t1_sec` (audio_chunk 내부 상대시간, 초)
- `search_queries` (TEXT[])
- (권장) `importance` (0..1, Phase 4 우선순위 힌트)

오디오 절대시간 규칙(SSOT):
- `signals.t0_sec/t1_sec`는 **audio_chunk 내부 상대시간**이다.
- 원본 오디오 절대시간은 `audio_chunks.start_offset_sec + signals.t0_sec`로 계산한다.

---

## 2) 사전조건: 오디오 청킹(Phase 0/1.5)
Phase 2는 원본 오디오를 한 번에 넣는 것보다, `audio_chunks` 단위로 처리하는 것을 표준으로 한다. [file:1]

- 입력 단위: `audio_chunks`(chunk_index, start_offset_sec 포함)
- 처리 단위: “청크 1개 → signals 여러 개 생성”
- 결과: signals는 반드시 `audio_chunk_id`에 연결된다. [file:1]

---

## 3) DB 스키마 최종 점검(DDL)
### 3.1 signals.search_queries 추가(없으면)
```sql
ALTER TABLE signals
ADD COLUMN IF NOT EXISTS search_queries TEXT[] DEFAULT '{}';
```

### 3.2 (권장) importance 컬럼이 없다면 추가
```sql
ALTER TABLE signals
ADD COLUMN IF NOT EXISTS importance FLOAT;

ALTER TABLE signals
ADD CONSTRAINT signals_importance_range
CHECK (importance IS NULL OR (importance >= 0 AND importance <= 1));
```

### 3.3 audio_chunk_id NOT NULL 확인(사실상 필수)
```sql
ALTER TABLE signals
ALTER COLUMN audio_chunk_id SET NOT NULL;
```

---

## 4) 워커 설계(Cloud Run Job) - Single Worker Parallelism (Updated v3.1)
### 4.1 아키텍처 변경 사항 (2026-01-07)
- **기존 설계**: 청크 개수만큼 새로운 Cloud Run Job 인스턴스를 트리거 (N chunks → N jobs).
- **최신 설계**: **단일 Cloud Run Job 인스턴스** 내에서 **ThreadPoolExecutor**를 사용하여 로컬 병렬 처리.
  - **이유**: 콜드 스타트 지연 제거, 리소스 관리 효율화, 클라우드 비용 절감, 단순화된 배포 구조.

### 4.2 Job 입력 (Dispatcher)
- `phase`: "split" (Dispatcher 모드 실행)
- `job-payload`:
  - `session_id`: 세션 ID
  - `gcs_audio_url`: 원본 오디오 전체 파일 URL (`gs://...`)
  - `subject`: 과목명 (Gemini 프롬프트 컨텍스트용)
  - `exam_window`: 시험 범위 (중간/기말 등)

### 4.3 처리 흐름 (Local Parallel Processing)
1. **Audio Analysis & Slicing**:
   - Dispatcher가 원본 오디오 시간을 확인하고 논리적 청크(예: 30분)로 계산.
   - DB `audio_chunks` 테이블에 청크 메타데이터 생성.
   - **(최적화)** `ffmpeg -c copy` 옵션을 사용하여 재인코딩(re-encoding) 없이 초고속으로 오디오 데이터 슬라이싱 (Stream Copy).

2. **Parallel Execution (ThreadPool)**:
   - Python `concurrent.futures.ThreadPoolExecutor(max_workers=50)` 초기화.
   - 각 청크 처리를 별도 스레드에 작업 할당.
   - Gemini API 호출은 **I/O Bound** 작업이므로 GIL(Global Interpreter Lock)의 영향을 받지 않고 높은 병렬성을 달성함.

3. **Signal Extraction (Worker Thread)**:
   - 각 스레드는 할당된 청크(URL 또는 Bytes)를 입력받아 Gemini 2.5 Flash Lite 모델 호출.
   - 추출된 JSON 응답 파싱 및 검증.

4. **Result Saving & Completion**:
   - 검증된 신호 데이터를 `signals` 테이블에 저장.
   - 모든 스레드 작업 완료(`wait`) 후 Session 상태를 `reasoning`(또는 다음 단계)으로 업데이트.

---

## 5) Gemini 호출 방식(오디오 입력)
### 5.1 GCS Direct Input(권장)
- 원칙: 다운로드 없이 `Part.from_uri("gs://...")` 형태로 입력(속도/비용 최적화)
- 실패 시에만 fallback으로 `/tmp` 다운로드 후 `from_data` 사용(선택)

### 5.2 구조화 출력 강제(필수)
Gemini 호출 파라미터(개념):
- `response_mime_type = "application/json"`
- `response_json_schema = (Phase 2 schema)`

이는 파싱 실패(마크다운 섞임/불완전 JSON)를 크게 줄이는 안정성 장치다. [file:1]

---

## 6) Phase 2 프롬프트(실사용, v3.0 언어정책 반영)
> **프롬프트는 영어(모델 이해/안정성), 출력 content는 한국어(사용자 친화)**를 강제한다. [file:1]

### 6.1 System Prompt (EN)
```text
[ROLE]
You are an exam-focused lecture analyzer. Your job is ONLY to extract exam-relevant signals from lecture audio and generate textbook search intents.

[NON_NEGOTIABLES]
- Output MUST be valid JSON matching the provided JSON Schema. No markdown, no extra keys, no explanations.
- Do NOT make any final exam predictions. This is Phase 2 only (no final classification or citations).
- Do NOT guess textbook pages, citations, source_id, or chunk_id. You only have the audio.
- Each signal MUST include 2 to 6 search_queries. 0 is not allowed.
- content MUST be: one sentence + (optional) one short reason in parentheses, max 160 Korean characters total.
- search_queries MUST be keyword-style (no long questions). Prefer official terms, formula names, chapter hints, English synonyms.
- If uncertain, produce a conservative signal with lower importance. Never fabricate evidence.

[LANGUAGE_POLICY]
- JSON keys must follow the schema exactly.
- signals[].content MUST be written in Korean (user-facing).
- search_queries may be Korean or English keywords (English is encouraged), but do NOT write long English sentences.

[INPUT]
You will receive:
- audio_chunk_id
- the audio content (or an audio reference)
- optional course context

[TASK]
Extract signals that likely matter for the exam:
- hint: explicit exam hints ("important", "will be on the exam", "pay attention")
- trap: confusion warnings ("don't mix up", "textbook differs", "common mistake")
- likely: repeated emphasis, repeated explanation, high importance topics

For each signal, generate search_queries to retrieve relevant textbook content.

[OUTPUT_SCHEMA]
Return JSON matching the schema.

[NOW_OUTPUT]
Return only the JSON.
```

### 6.2 User Prompt (EN wrapper)
```text
[INPUT]
session_id="{SESSION_ID}"
audio_chunk_id="{AUDIO_CHUNK_ID}"
exam_window="{EXAM_WINDOW}"
subject="{SUBJECT_NAME}"
(optional) professor_style_notes="{USER_NOTES}"

Audio:
{AUDIO_PART_FROM_URI_OR_REFERENCE}

[TASK]
Extract signals + search intent as specified.
[NOW_OUTPUT]
```

---

## 7) Phase 2 response_json_schema (최종)
```json
{
  "type": "object",
  "additionalProperties": false,
  "required": ["signals"],
  "properties": {
    "signals": {
      "type": "array",
      "items": {
        "type": "object",
        "additionalProperties": false,
        "required": [
          "signal_type",
          "content",
          "search_queries",
          "audio_chunk_id",
          "t0_sec",
          "t1_sec",
          "importance"
        ],
        "properties": {
          "signal_type": {
            "type": "string",
            "enum": ["hint", "likely", "trap"]
          },
          "content": {
            "type": "string",
            "minLength": 1,
            "maxLength": 200
          },
          "search_queries": {
            "type": "array",
            "minItems": 2,
            "maxItems": 6,
            "items": {
              "type": "string",
              "minLength": 2,
              "maxLength": 120
            }
          },
          "audio_chunk_id": {
            "type": "string",
            "minLength": 8,
            "maxLength": 64
          },
          "t0_sec": { "type": "number", "minimum": 0 },
          "t1_sec": { "type": "number", "minimum": 0 },
          "importance": { "type": "number", "minimum": 0, "maximum": 1 }
        }
      }
    }
  }
}
```

---

## 8) 저장 로직(서버 검증 포함)
### 8.1 응답 검증(필수)
signals 배열을 순회하며 다음을 검증한 뒤 INSERT 한다.
- `content` 비어있음 금지
- `search_queries` 길이 2~6 준수
- `t0_sec <= t1_sec`
- `audio_chunk_id`가 요청한 chunk와 일치(또는 최소한 동일 세션의 chunk인지)  
- `importance`가 0..1

### 8.2 INSERT 규칙(권장)
- “완전 중복 신호”가 많이 나올 수 있으므로, (선택) `(session_id, audio_chunk_id, t0_sec, t1_sec, content)` 기반 중복 방지 키를 둘 수 있다.
- 단, 너무 강한 dedup은 Recall을 해칠 수 있어 “운영 옵션”으로 둔다(기본은 중복 허용). [file:1]

---

## 9) 검증 시나리오(Test Plan)
### Scenario A: 힌트 명시형 강의
- 기대: hint 타입 신호가 다수 나오고, search_queries가 교재 용어/공식 기반으로 생성됨.

### Scenario B: 함정/예외 강조 강의
- 기대: trap 타입 신호가 생성되고, content가 “헷갈리는 포인트”를 한국어로 단정적으로 요약함.

### Scenario C: 대용량 오디오(여러 청크)
- 기대: 각 chunk에 대해 signals가 생성되고, UI가 `(audio_chunk_id, t0_sec~t1_sec)`로 정확히 재생 가능함.

---

## 10) Definition of Done
- Signal Extractor Job(Cloud Run Job) 구현 완료
- 임의 세션에 대해:
  - signals가 DB에 저장되고
  - 각 signal에 search_queries(2~6)가 존재하며
  - 타임코드가 정상(t0<=t1)이고
  - content가 한국어로 읽히는 수준으로 구체적임 [file:1]
```