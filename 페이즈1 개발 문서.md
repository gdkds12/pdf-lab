```markdown
# Project Thunder 개발 작업 지시서 (Phase 1)
## Phase 1: Cloud Run Native PDF Ingest Pipeline (v3.0 최신)

> 본 문서는 Project Thunder v3.0의 **교재(PDF) 지식베이스 구축 파이프라인**(Phase 1) 개발 지침이다. [file:1]  
> 핵심 목표는 `GCS URI 입력 → (Router) Digital/Scanned 분기 → (Parse/OCR) 페이지 보존 전사 → Chunking(메타 포함) → Embedding(gemini-embedding-001) → OCI Supabase(chunks) 적재` 이다. [file:1]

---

## 1. 개요 및 목표
Phase 1은 이후 Phase 3 하이브리드 검색과 Phase 4 “메타 포함 블록(citations)”을 성립시키기 위해, **청크에 page/anchor/ID가 정확히 남는 형태**로 교재를 구조화한다. [file:1]  
특히 Scanned PDF는 Gemini를 사용하되, “요약/재배열”로 인해 페이지 매핑이 깨지지 않도록 **전사 정책을 강제**한다. [file:1]

---

## 2. 기술 스택 및 환경
- Runtime: Python 3.10+ (Dockerized, Cloud Run Jobs)  
- Infrastructure:
  - Compute: GCP Cloud Run Jobs (권장: CPU 2+, Memory 4GiB+; 대용량/스캔본은 8GiB 고려)
  - Storage: GCS(Input), Local `/tmp`(ephemeral)
  - AI/ML:
    - Gemini: `gemini-2.5-flash-lite` (OCR/Parsing/구조화 전사) [file:1]
    - Embedding: `gemini-embedding-001` (768d) [file:1]
  - DB: OCI Supabase(Postgres + pgvector/halfvec) → `chunks` 테이블 적재 [file:1]
- Key Libraries(권장):
  - `google-cloud-storage`, `google-cloud-aiplatform`
  - `pymupdf`(fitz)
  - `supabase`
  - `tenacity`
  - (옵션) `tiktoken` 또는 자체 토큰 추정기(Phase 4 예산용 token_count 계산)

---

## 3. 입력/출력 계약(SSOT)
### 입력
- `source_id` (DB에 이미 등록된 교재/노트 소스 ID)
- `gcs_pdf_url` 또는 `gs://bucket/path.pdf`

### 출력
- Supabase `chunks` 테이블에 row N개 삽입/업서트 [file:1]
  - 필수: `source_id`, `content_text`, `embedding(halfvec 768)`, `page_start`, `page_end`, `anchor_path[]` [file:1]
  - 권장: `token_count` (간이 계산: 문자수/4), `content_hash` (현재 미구현, 필요 시 추가) [file:1]

---

## 4. 단계별 개발 상세 (Step-by-Step) & 구현 현황 (v3.1)

### Step 0. Cloud Run Job 스캐폴딩 / Docker
- Base image: `python:3.10-slim`
- 불필요한 OS 패키지 설치 최소화(PyMuPDF용 build-essential, ffmpeg 포함)

### Step 1. Ingest Pipeline 구현
- **Scanned PDF 처리**:
  - `fitz`(PyMuPDF)로 페이지를 이미지화하지 않고, Gemini 2.5 Flash-lite에 PDF 파트를 직접 전달하여 OCR 수행 (`Part.from_data`).
  - **Batch Processing**: 20페이지 단위로 배치를 나누어 `ThreadPoolExecutor` (max 100 threads)로 병렬 전사 수행.
- **Chunking Logic**:
  - **Paragraph-based**: `\n\n` 기준으로 문단을 나누고, 최대 1000자 단위로 병합.
  - Page Boundary: 페이지 단위 메타데이터(`page_start`, `page_end`) 보존.
- **Embedding**:
  - `gemini-embedding-001` 사용 (Vertex AI).
  - 배치 크기: 8 (API 제한 고려).

### Step 2. DB Schema & Indexing
- `chunks` 테이블: `halfvec(768)` 컬럼 사용.
- Index:
  - Vector: `hnsw (embedding halfvec_cosine_ops)`
  - Keyword: `gin (content_text gin_trgm_ops)`  
- 환경변수(예시):
  - `GCP_PROJECT`, `GCP_LOCATION`
  - `SUPABASE_URL`, `SUPABASE_SERVICE_ROLE_KEY`
  - `INGEST_BATCH_PAGES=20` (Scanned 분할 기본값)
  - `EMBED_BATCH_SIZE=8` (임베딩 배치)

**Check**
- 로컬 Docker 빌드/실행, GCS 접근, Supabase 연결이 모두 성공하는지.

---

### Step 1. GCS 다운로드 (메모리 안정성)
- `gs://` URI를 파싱해 bucket/blob 추출
- 다운로드 경로: `/tmp/{uuid}.pdf`
- 처리 후 `finally`에서 무조건 삭제

**Check**
- 100MB+ PDF 다운로드 시 RSS 메모리가 급증하지 않고 `/tmp`로 안정적으로 저장되는지.

---

### Step 2. Router (Digital vs Scanned)
목표: 전체 문서를 한 번에 OCR로 보내지 않고, “필요할 때만” Gemini를 사용하도록 분기한다. [file:1]

**Logic**
1. `fitz.open(local_pdf_path)`
2. 첫 3페이지 `page.get_text("text")` 수행
3. 텍스트 밀도(예: “페이지당 글자수 평균”)가 임계값 미만이면 `SCANNED`, 이상이면 `DIGITAL`

**권장 보강**
- “3페이지 중 2페이지 이상이 임계값 미만” 같은 다수결 룰로 오분류를 줄인다.
- Router 결과를 `sources.ingest_status` 또는 별도 로그 테이블에 남겨 재현성 확보(선택). [file:1]

---

### Step 3A. DIGITAL 트랙: PyMuPDF 텍스트 추출(빠른 경로)
DIGITAL은 **Gemini 미사용**을 기본으로 하여 비용/지연을 최소화한다. [file:1]

**Logic**
- 페이지별로 텍스트를 추출하고, “페이지 번호 보존” 상태로 파이프라인에 넘긴다.
- 출력 포맷(내부 표준, 예시):
```json
{
  "pages": [
    { "page_num": 1, "text": "..." },
    { "page_num": 2, "text": "..." }
  ]
}
```

**주의**
- DIGITAL에서도 header/section 구조(anchor 후보)가 필요하므로, 최소한의 헤더 감지(예: 대문자 라인, 번호 패턴) 또는 “약식 anchor_path=['Page 10']”라도 반드시 채운다(후속 citations 안정성). [file:1]

---

### Step 3B. SCANNED 트랙: PDF 분할 + Gemini OCR/Parsing(핵심)
SCANNED는 “페이지 매핑이 절대 깨지지 않는 전사”가 목표다. [file:1]

#### (1) PDF Splitting (Batching)
- 기본: 20페이지 단위 sub-PDF로 분할 [file:1]
- 구현: `fitz.Document()`에 `insert_pdf()`로 범위 복사 후 `tobytes()`로 bytes 생성
- 각 배치에는 메타를 붙인다:
  - `batch_index`, `page_start`, `page_end` (원본 기준)

**Check**
- 배치 순서가 유지되고(page_start/end), 누락 없이 전체 페이지가 커버되는지.

#### (2) Gemini 호출 (application/pdf 직접 전달)
- `Part.from_data(pdf_bytes, mime_type="application/pdf")` 형태로 전달(이미지 변환 파이프라인 제거)
- Retry: `tenacity`로 429/5xx에 대해 지수 백오프

#### (3) OCR/Parsing 출력 포맷(페이지 보존 강제)
요약/재배열로 매핑이 깨지는 것을 막기 위해, 출력은 “페이지 단위 JSON”으로 고정하는 것을 권장한다. [file:1]

- Gemini에 강제할 내부 출력(JSON) 예시:
```json
{
  "pages": [
    {
      "page_num": 45,
      "markdown": "..."
    }
  ]
}
```

- 전사 정책(프롬프트에 반드시 포함):
  - 누락 금지 / 요약 금지 / 재정렬 금지
  - 표는 Markdown Table, 수식은 LaTeX로 구조 유지
  - 페이지 번호를 정확히 유지(배치 시작 페이지 기준 오프셋 적용)

**Check**
- 수식/표가 구조를 유지하는지, 페이지 번호가 원본과 일치하는지.

---

### Step 4. Chunking (메타 포함, SSOT 준수)
Phase 3/4를 위해 “청크 메타데이터”가 가장 중요하다. [file:1]

#### (1) Anchor 추출(권장)
- 우선순위:
  1. Markdown heading 기반(`##`, `###`)
  2. 번호 패턴(예: `3.2`, `Definition`, `Theorem`)
  3. fallback: `anchor_path=["Page {page_num}"]`

#### (2) Chunk 생성 규칙(권장 기본)
- 1차: heading 단위로 split
- 2차: 길이 초과 시 문단 단위 split
- 각 chunk에는 반드시:
  - `page_start`, `page_end` (최소 동일 페이지라도 채움)
  - `anchor_path[]` (최소 1개 요소)
  - `content_text` (검색/인용 원문)

#### (3) content_hash / token_count (권장)
- `content_hash`: `(source_id + normalized_text)` 해시로 생성(재실행 시 idempotency)
- `token_count`: Phase 4 예산 기반 context assembly를 위한 값(없으면 서버가 추정) [file:1]

**Check**
- chunk가 너무 잘게 쪼개져 검색 품질이 떨어지지 않는지(“의미 단위” 유지).
- page_start/end와 anchor_path가 비어 있는 row가 절대 생성되지 않는지.

---

### Step 5. Embedding (gemini-embedding-001, 768d)
- 모델: `gemini-embedding-001` [file:1]
- 배치: 5~10개 묶음 요청(호출 수 절감)
- 오류 처리: 부분 실패 시 실패한 청크만 재시도(전체 롤백 금지)

**Check**
- embedding 차원이 768로 고정되는지, 빈 문자열이 들어가지 않는지.

---

### Step 6. DB 적재 (OCI Supabase → chunks)
Target: `chunks` 테이블 [file:1]

권장 payload(SSOT v3.0 기준):
```python
{
  "source_id": source_id,
  "content_text": chunk_text,
  "embedding": embedding_vector,    # List[float] (서버/DB에서 halfvec로 캐스팅/저장)
  "page_start": page_start,
  "page_end": page_end,
  "anchor_path": anchor_path,       # List[str]
  "content_hash": content_hash,     # 권장
  "token_count": token_count        # 권장
}
```

**업서트/중복 방지**
- `content_hash` 기반 unique index가 있으면 upsert로 재실행 안정성 확보(권장). [file:1]

**Check**
- Supabase에서 row 조회 가능 + embedding 컬럼 채워짐
- page_start/end, anchor_path가 누락된 row가 없는지

---

## 5. 디버깅 및 검증 시나리오 (Test Plan)
### Scenario A: Digital PDF 처리(빠른 경로)
- 입력: 텍스트 선택 가능한 PDF(논문/전자책)
- 기대:
  - Router: DIGITAL
  - Gemini 미사용(또는 최소화)
  - DB 저장 속도가 빠름 [file:1]

### Scenario B: Scanned PDF 처리(OCR 경로)
- 입력: 드래그 불가 이미지형 PDF(스캔본)
- 기대:
  - Router: SCANNED
  - 20페이지 단위 분할 → Gemini OCR JSON(page 보존) → chunking → DB 저장 [file:1]

### Scenario C: 대용량 안정성(100p+)
- 입력: 100페이지 이상 PDF
- 기대:
  - OOM 없이 완주
  - 배치 단위로 진행되며 중간 실패 시 부분 재시도 가능 [file:1]

---

## 6. 산출물(Definition of Done)
- `thunder-ingest-worker` Cloud Run Job 이미지
- 다음이 포함된 실행 로그:
  - Router 판정(DIGITAL/SCANNED)
  - SCANNED 배치 처리 진행률(page_start/end)
  - chunk 개수, embedding 배치 수, DB 삽입/업서트 건수
- Scenario A/B/C 전부 통과 증적(로그 + Supabase 샘플 row) [file:1]

---

## 7. 구현 상세 (Implementation Details - 2026.01)

### 7.1 Backend 구조
- **언어 및 프레임워크**: Python 3.10, Docker, Cloud Run Jobs
- **설정 관리**: `backend/src/shared/config.py`을 통해 환경변수 로드 (`dotenv` 사용)
- **주요 파일**:
  - [`backend/src/phase1/ingest_pipeline.py`](backend/src/phase1/ingest_pipeline.py): 전체 파이프라인 로직 포함 (`IngestPipeline` 클래스)
  - [`backend/Dockerfile`](backend/Dockerfile): `gcloud builds` 용 컨테이너 정의

### 7.2 단계별 구현 현황
1.  **초기화 및 다운로드**:
    -   `StorageClient` (`backend/src/shared/storage.py`)를 통해 GCS 버킷에서 로컬 `/tmp/{uuid}.pdf`로 다운로드.
    -   `uuid`를 사용하여 동시 실행 시 파일명 충돌 방지.

2.  **Router (Digital vs Scanned)**:
    -   `_router_check` 메서드 구현. 처음 3페이지의 텍스트 밀도(글자 수 50 미만)를 검사하여 Scanned 여부 판단. 과반수(3페이지 중 2페이지 이상) 로직 적용.

3.  **텍스트 추출 (Parallel/Sequential)**:
    -   **Digital**: `fitz` (PyMuPDF)를 사용하여 페이지별 `get_text()` 호출.
    -   **Scanned**: 
        -   PDF를 20페이지 단위(Batch)로 분할하여 서브 PDF 생성.
        -   `vertexai.generative_models.GenerativeModel` 사용 (`gemini-2.5-flash-lite`).
        -   **Prompt**: JSON 포맷 강제, 페이지 번호 보정 요구, 마크다운 표/수식 보존 요청.
        -   현재 순차(Sequential) 처리 방식 구현 (추후 병렬화 가능).

4.  **Chunking**:
    -   `_chunk_text` 메서드. 문단(`\n\n`) 기반의 단순 분할 구현.
    -   최대 글자 수 1000자 제한, 초과 시 분할.
    -   메타데이터(`page_start`, `page_end`, `source_id`) 보존.

5.  **Embedding**:
    -   모델 변경: `text-embedding-004` -> **`gemini-embedding-001`** 교체 완료.
    -   `vertexai.language_models.TextEmbeddingModel` 사용.
    -   8개 청크 단위로 배치 처리하여 API 호출 효율화.

6.  **DB 적재**:
    -   Supabase Python 클라이언트 사용.
    -   `chunks` 테이블에 배치(100개) 단위 `insert`.
    -   `ingest_status` 필드를 `running` -> `succeeded` / `failed`로 업데이트하며 진행 상황 추적.

---

## 8. 개발 및 테스트 가이드

### 8.1 흐름 요약
1.  **가상환경 준비** (`venv`)
2.  **환경변수 설정** (`.env`)
3.  **로컬 테스트** (`setup_test_data.py` -> `test_local_ingest.py`)
4.  **배포** (`gcloud builds` -> `gcloud run jobs update`)

### 8.2 로컬 개발 환경 세팅
1.  **Python 가상환경 생성**:
    ```powershell
    cd backend
    python -m venv venv
    .\venv\Scripts\activate
    ```
2.  **의존성 설치**:
    ```powershell
    pip install -r requirements.txt
    ```
3.  **환경변수 설정**:
    `backend/.env` 파일을 생성하고 다음 내용을 채워넣으세요.
    ```ini
    GCP_PROJECT=pdf-lab-468815
    GCP_LOCATION=asia-northeast3 (또는 us-central1)
    GCS_BUCKET_NAME=your-bucket-name
    SUPABASE_URL=https://your-project.supabase.co
    SUPABASE_SERVICE_ROLE_KEY=your-service-role-key
    EMBEDDING_MODEL_NAME=gemini-embedding-001
    ```

### 8.3 로컬 테스트 실행 방법
실제 Cloud Run에 배포하기 전, 로컬에서 전체 파이프라인을 테스트할 수 있는 스크립트가 준비되어 있습니다.

1.  **테스트 데이터 생성 및 업로드**:
    Dummy PDF를 생성하고 GCS에 업로드하며, Supabase `sources` 테이블에 메타데이터를 등록합니다.
    ```powershell
    python scripts/setup_test_data.py
    ```
    *결과: `source_id`와 `gcs_uri`가 출력됨.*

2.  **로컬 Ingest 파이프라인 실행**:
    위에서 얻은 ID와 URI를 사용하여 파이프라인을 실행합니다. (스크립트 내 `source_id` 등의 수정이 필요할 수 있습니다)
    ```powershell
    python scripts/test_local_ingest.py
    ```
    *정상 실행 시: 파이프라인 로그가 출력되고, Supabase `chunks` 테이블에 데이터가 적재됩니다.*

### 8.4 배포 (Cloud Build & Run)
코드가 수정되면 다음 명령어로 이미지를 빌드하고 Cloud Run Job을 업데이트해야 합니다.

1.  **이미지 빌드 및 푸시**:
    ```powershell
    gcloud builds submit --tag asia-northeast3-docker.pkg.dev/pdf-lab-468815/thunder-backend-repo/pdf-processor:latest
    ```

2.  **Cloud Run Job 업데이트**:
    ```powershell
    gcloud run jobs update thunder-worker --image asia-northeast3-docker.pkg.dev/pdf-lab-468815/thunder-backend-repo/pdf-processor:latest --region asia-northeast3
    ```
```
